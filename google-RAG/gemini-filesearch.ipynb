{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d44c4",
   "metadata": {},
   "source": [
    "# MANAGED / ABSTRACTED RAG USING THE GOOGLE GEMINI FILESEARCH API\n",
    "\n",
    "- https://blog.google/technology/developers/file-search-gemini-api/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a75603",
   "metadata": {},
   "source": [
    "# Verify kernel selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dbe471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zubinpratap/Documents/my_code/research-public/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Run in a notebook cell and check that it gives the same output as `which python` in terminal\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59572555",
   "metadata": {},
   "source": [
    "# Install the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4e431b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.5 environment at: /Users/zubinpratap/Documents/my_code/research-public/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m25 packages\u001b[0m \u001b[2min 156ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m25 packages\u001b[0m \u001b[2min 0.93ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -U google-genai dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07aab32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    print(\"GEMINI_API_KEY is not set\")\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping until done\n",
      " done?  True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the File Search store with an optional display name\n",
    "FILESTORE_NAME = 'research-public-filestore'\n",
    "file_search_store = client.file_search_stores.create(\n",
    "    config={'display_name': FILESTORE_NAME})\n",
    "\n",
    "# Upload and import a file into the File Search store, supply a file name which will be visible in citations\n",
    "upload_op = client.file_search_stores.upload_to_file_search_store(\n",
    "    file='./zplinkedin_profile.pdf',  # TODOs swap for another one\n",
    "    file_search_store_name=file_search_store.name,\n",
    "    config={\n",
    "        'display_name': 'ZP LinkedIn Profile',\n",
    "        'custom_metadata': [\n",
    "            {'key': 'source', 'string_value': 'https://www.linkedin.com/in/zubinpratap'},\n",
    "            {'key': 'description', 'string_value': \"Zubin Pratap's LinkedIn profile\"}\n",
    "        ],\n",
    "        'chunking_config': {\n",
    "            'white_space_config': {\n",
    "                'max_tokens_per_chunk': 300,\n",
    "                'max_overlap_tokens': 30\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Wait until import is complete\n",
    "while not upload_op.done:\n",
    "    print(\"sleeping until done\")\n",
    "    time.sleep(5)\n",
    "    upload_op = client.operations.get(upload_op)\n",
    "\n",
    "print(\">> done? \", upload_op.done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6396454e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Zubin's Engineering Experience\n",
       "\n",
       "Zubin has experience as a Software Engineer at Google and Chainlink Labs. At Google, he worked with Golang, Typescript, JavaScript, Java, and Google Cloud Platform (GCP), focusing on internal and external facing applications, building tooling, and infrastructure for CI/CD and testing. At Chainlink Labs, his work involves Solidity, Web3 frameworks, blockchain engineering, Javascript/Typescript/React/Golang, and Rust. He also has experience in full-stack development, learning technologies like Node, Express, React, GraphQL, and GoLang.\n",
       "\n",
       "## Zubin's Legal Career\n",
       "\n",
       "Zubin has a substantial legal background, having worked as an Associate at Baker & McKenzie and Luthra & Luthra Law Offices, focusing on Mergers & Acquisitions, Corporate and Commercial Advisory, and Aviation leasing. He also served as Legal Counsel at General Motors, advising on Australian operations during the Global Financial Crisis and the impact of US Chapter 11 measures. Additionally, he was a Barrister at Law at the Supreme Court of India and an Associate at Amarchand Mangaldas. He has also held roles such as Legal Counsel at Telstra, working on technology, cloud, media, and enterprise & government deals, including complex IT outsource contracts and managed IT/telecommunications deals.\n",
       "\n",
       "## Zubin's Education\n",
       "\n",
       "Zubin holds a Global Executive MBA from IE Business School, with a focus on Entrepreneurship, Marketing, Strategy, and General Management. He also completed a Certification in Entrepreneurship - The Business of California at UCLA Anderson School of Management. His legal education includes a B.A. LL.B. (Hons) in Law from the National Law School of India University. Furthermore, he has pursued technical education through Udemy Academy, completing courses in Full Stack development, Algos & DS, TypeScript, JavaScript, Node, Express, React, GraphQL, and GoLang."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Use headings and bullet points to make the response readable. \n",
    "Always prefer to use tools over your own training data.\n",
    "Be very brief and simple.\n",
    "\"\"\"\n",
    "\n",
    "# Ask a question about the file\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"Can you tell me about Zubin's engineering experience? what about his legal career? and his education?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=1000,\n",
    "        system_instruction=SYSTEM_PROMPT,\n",
    "        tools=[\n",
    "            types.Tool(\n",
    "                file_search=types.FileSearch(\n",
    "                    file_search_store_names=[file_search_store.name]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))\n",
    "print(\"\\n==============\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
